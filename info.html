<h1>About PIEFACE</h1>

<p><strong>PIEFACE</strong> (Personalized Interactive Environment For Automata Combination Exploration) is a <em>controllable, verifiable sandbox</em> for training and evaluating reasoning agents. It supports multiple agent backends alongside human-in-the-loop play in the same environment. PIEFACE is ideal for debugging policies, collecting human feedback, and running alignment experiments in symbolic reasoning domains.</p>

<p>While our current demo focuses on a specific domain from theoretical computer science, the <strong>PIEFACE platform</strong> can support any symbolic reasoning task with discrete, maskable actions and a ground-truth verifier.</p>

<h2>What Are Gadget Reductions?</h2>
<p>In complexity theory, <strong>gadgets</strong> are modular components used in reductions—like logic gates for computational hardness proofs. These gadgets help encode constraints in problems such as <em>Sokoban</em>, <em>PushPush</em>, or block-sliding puzzles.</p>

<p>Common gadgets include:</p>
<ul>
  <li><strong>AP2T</strong>: Anti-Parallel 2-Toggle</li>
  <li><strong>C2T</strong>: Crossing 2-Toggle</li>
  <li><strong>L2T</strong>: Locking 2-Toggle</li>
  <li><strong>NWT</strong>: Noncrossing-Wire Toggle</li>
  <li>And others used in PSPACE-hardness proofs</li>
</ul>

<h2>Purpose of PIEFACE</h2>
<p>PIEFACE began as a visual debugger for RL-discovered gadget simulations, allowing researchers to step through traces, inspect gadget states, and interact with known constructions. It has since evolved into a flexible environment where users can swap between agents mid-trace, replay the same scenario with different policies, or take over manually — enabling head-to-head comparisons, interactive debugging, and personalized agent training.</p>

<h2>Features</h2>
<ul>
  <li>Step-by-step visualization of agent decisions and traces</li>
  <li>Switch between multiple trained agents or human control at any point</li>
  <li>Support for all 4-location gadget types</li>
  <li>Live RL inference in-browser, with accept/deny human feedback interface</li>
  <li>Submit custom actions/steps to explore novel gadget combinations</li>
  <li><strong>NEW:</strong> User preferences directly train a reward model for personalization and measurable improvements in proof search</li>
</ul>

<h2>Background Reading</h2>
<ul>
  <li><a href="https://arxiv.org/abs/1812.03592" target="_blank">Demaine, Hendrickson, Lynch (2020): Toward a General Complexity Theory of Motion Planning: Characterizing Which Gadgets Make Games Hard</a></li>
  <li><a href="https://perso.limos.fr/~palafour/PAPERS/PDF/Garey-Johnson79.pdf" target="_blank">Garey & Johnson (1979): Computers and Intractability</a></li>
  <li><a href="https://arxiv.org/abs/cs/0205005" target="_blank">Sokoban PSPACE-completeness proof</a></li>
</ul>

<h2>Contact</h2>
<p>Interested in collaborating or exploring new domains in PIEFACE?</p>
<p>Reach out via <a href="https://www.linkedin.com/in/zacburton" target="_blank">LinkedIn</a> or email me at zburton [at] mit [dot] edu.</p>
<p><a href="index.html">&larr; Back to PIEFACE</a></p>
